{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.split() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "elif api_key[:8] != \"sk-proj-\":\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "else :\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3269e2e-9089-4c29-919d-1b93b3b4a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai=OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e3781c7-a685-4fcc-8fbd-0e7768f09a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful programming tutor.\n",
    "You will be given a coding question or snippet.\n",
    "Your job is to explain what the code does and why it works in a way that is very easy for a beginner to understand.\n",
    "\n",
    "Requirements:\n",
    "1. Use simple, beginner-friendly language (avoid jargon unless you also explain it).\n",
    "2. Break down the code step by step.\n",
    "3. Explain both *what* the code does and *why* it is written that way.\n",
    "4. Use small examples or analogies if it helps clarity.\n",
    "5. Keep the explanation short, clear, and approachable.\n",
    "6. Respond in Markdown format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b011c75-2a21-4069-be00-3e41832681cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(question):\n",
    "    user_prompt = \"\"\n",
    "    user_prompt += \"You will be given a question.\\n\"\n",
    "    user_prompt += \"Your task is to explain the answer in a way that is simple and beginner-friendly.\\n\"\n",
    "    user_prompt += \"Always respond in Markdown format for clarity.\\n\\n\"\n",
    "    user_prompt += \"Here is the question:\\n\"\n",
    "    user_prompt += question\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "413b34fa-511d-4e76-8d09-b447a7caedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role':'user','content':user_prompt_for(question)},\n",
    "    {'role':'system','content':system_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "def get_answer(question):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model = MODEL_GPT,\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    )\n",
    "    response = \" \"\n",
    "    display_handle = display(Markdown(\"\"),display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace('```','').replace('markdown','')\n",
    "        update_display(Markdown(response), display_id = display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae45b685-cdf4-47cb-8583-5584f507ebdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Sure! Let’s break down the code step-by-step to understand what it does and why it's written that way.\n",
       "\n",
       "### Code Breakdown\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "1. **`books`**: This is likely a collection, such as a list, of dictionaries where each dictionary represents a book. For example:\n",
       "\n",
       "   python\n",
       "   books = [\n",
       "       {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "       {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "       {\"title\": \"Book 3\", \"author\": None},  # No author\n",
       "       {\"title\": \"Book 4\", \"author\": \"Author A\"}\n",
       "   ]\n",
       "   \n",
       "\n",
       "2. **List Comprehension**: The code inside the curly braces `{ ... }` is using a feature called a \"set comprehension.\" This is similar to list comprehension, but it creates a set, which is a type of collection that only keeps unique items (no duplicates).\n",
       "\n",
       "   - Here, `book.get(\"author\") for book in books` means \"for each `book` in the `books`, get the `author` of that book.\"\n",
       "\n",
       "3. **Filtering with `if`**: The part `if book.get(\"author\")` checks if the author exists (not `None`). If an author is present, that name is included in the set. If there's no author (like in Book 3), it won't be added.\n",
       "\n",
       "4. **`yield from`**: This is a way to return values from a generator function. When this part runs, it gives back each author from the set one by one when needed, instead of all at once.\n",
       "\n",
       "### What Does This Code Do?\n",
       "\n",
       "When you put it all together, this code does the following:\n",
       "\n",
       "- It goes through each book in a list called `books`.\n",
       "- It retrieves the author's name for each book, but only if that name exists.\n",
       "- It collects all the unique authors into a set (which automatically removes duplicates).\n",
       "- It then provides a way to get each author one at a time when you ask for them, thanks to `yield from`.\n",
       "\n",
       "### Why Is It Written This Way?\n",
       "\n",
       "- **Efficiency**: By using a set, it automatically removes duplicate authors, so you only get distinct names.\n",
       "- **Readability**: The use of comprehensions makes the code cleaner and more compact.\n",
       "- **Lazy Evaluation**: Using `yield from` allows you to produce values only as needed, which can save memory if you're working with large data sets; you don’t hold everything in memory at once.\n",
       "\n",
       "### Quick Example\n",
       "\n",
       "If we take our example `books`, the output of this code would be:\n",
       "\n",
       "python\n",
       "{\"Author A\", \"Author B\"}\n",
       "\n",
       "\n",
       "This means you have two distinct authors, \"Author A\" and \"Author B\". \"Author A\" only appears once, even though they wrote two books.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "In summary, this code is a smart, efficient way to get a unique list of authors from a collection of books while ensuring that you only consider books that have authors listed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b416ca54-2510-4337-9d7c-fc3ded455c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b61c696-996c-47d6-803f-893c01005db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_ollama= [\n",
    "    {'role':'user','content':user_prompt_for(question)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "562f02e9-a31b-4276-8b8c-77306f914b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'messages' : messages_ollama,\n",
    "    'stream' : False,\n",
    "    'model' : MODEL_LLAMA\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7069e1ac-aadf-43e3-a235-dfb30431b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = requests.post(OLLAMA_API ,json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "933a0a48-d5b8-4946-b806-1659d9091418",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_via_openai = OpenAI(base_url = \"http://localhost:11434/v1\", api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "def get_answers_open_source(question):\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        messages = messages_ollama,\n",
    "        model = MODEL_LLAMA\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99a108ea-d620-4c5c-90a6-dac18f9f11bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Understanding Generator Expressions**\n",
       "=====================================\n",
       "\n",
       "### Broken Down Explanation\n",
       "\n",
       "The provided code snippet utilizes a feature called \"generator expressions\" or \"list comprehensions with `yield from`\".\n",
       "```python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "Let's break it down:\n",
       "\n",
       "*   **List Comprehension**: The `{...}` part is similar to a list comprehension in Python, but instead of creating an actual list, it yields values one by one.\n",
       "*   `for book in books`: This loop goes through each item (book) in the `books` collection.\n",
       "*   `if book.get(\"author\")`: It filters out only those books that have an 'author' key present in their dictionary (`book`). If a book does not have this key, it is skipped.\n",
       "\n",
       "**What the Code Does**\n",
       "-------------------\n",
       "\n",
       "The code generates all authors from the filtered list of books. \n",
       "\n",
       "Here's how:\n",
       "\n",
       "*   When one book has an author, this value will be included.\n",
       "*   When no such book exists for which its \"author\" is found (None), there won't be any values generated.\n",
       "\n",
       "**Why it's Used**\n",
       "----------------\n",
       "\n",
       "Generator expressions with `yield from` provide the benefit of iterating through every item more efficiently than using regular for loops. \n",
       "\n",
       "They offer the following advantages:\n",
       "\n",
       "1.  **Memory Efficiency**: Instead of loading and storing all items in memory at once, it loads just one value (and only that many). \n",
       "    This feature is very efficient with large data sets, especially those stored as files.\n",
       "2.  **Lazy Evaluation**: It uses lazy evaluation to evaluate expressions that are computed and returned on demand by these generators.\n",
       "3.  **Higher Memory Usage but Lower Memory Access Time**\n",
       "\n",
       "*   Instead of loading the whole item list into memory at once\n",
       "*   loads one element at a time, which is typically faster than accessing that many elements before\n",
       "\n",
       "**When to Use it**\n",
       "------------------\n",
       "\n",
       "This type of code should be used whenever:\n",
       "\n",
       "1.  *Efficiency Matters*: If you're dealing with massive data sets.\n",
       "2.  *Storage Space is limited*: When every bit counts or space must be kept to the minimum required, \n",
       "    such as an embedded system environment.\n",
       "\n",
       "*   There are many more scenarios in which this can come up\n",
       "\n",
       "    - In real-time applications where resources might get occupied, the code here would be quite optimal.\n",
       "\n",
       "In summary, Python's generator expression provides a powerful tool for dealing with large items without having to load every single one into memory at once."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(display(Markdown(get_answers_open_source(question))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f68ed4-5051-4f66-b182-7db7f40e60c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
